{
    "A100-PCIex1": {
        "config_ver": {
            "triton": {
                "instance_group_count": 4,
                "server_target_qps": 786,
                "use_triton": true
            }
        },
        "deque_timeout_us": 30000,
        "gpu_batch_size": 8,
        "gpu_inference_streams": 4,
        "server_target_qps": 800,
        "use_cuda_thread_per_device": true
    },
    "A100-PCIex2": {
        "config_ver": {
            "triton": {
                "instance_group_count": 4,
                "server_target_qps": 1572.5,
                "use_triton": true
            }
        },
        "deque_timeout_us": 30000,
        "gpu_batch_size": 8,
        "gpu_inference_streams": 4,
        "server_target_qps": 1600,
        "use_cuda_thread_per_device": true
    },
    "A100-PCIex8": {
        "scales": {
            "A100-PCIex1": {
                "server_target_qps": 8.0
            }
        }
    },
    "A100-SXM-80GBx1": {
        "extends": [
            "A100-SXM4-40GBx1"
        ]
    },
    "A100-SXM-80GBx1-MIG_1x1g.10gb": {
        "extends": [
            "T4x1"
        ]
    },
    "A100-SXM-80GBx8": {
        "extends": [
            "A100-SXM4-40GBx8"
        ]
    },
    "A100-SXM-80GBx8-MIG_56x1g.10gb": {
        "scales": {
            "A100-SXM-80GBx1-MIG_1x1g.10gb": {
                "server_target_qps": 56
            }
        }
    },
    "A100-SXM4-40GBx1": {
        "config_ver": {
            "triton": {
                "instance_group_count": 4,
                "server_target_qps": 925,
                "use_triton": true
            }
        },
        "deque_timeout_us": 30000,
        "gpu_batch_size": 8,
        "gpu_inference_streams": 4,
        "server_target_qps": 925,
        "start_from_device": true,
        "use_cuda_thread_per_device": true
    },
    "A100-SXM4-40GBx8": {
        "config_ver": {
            "triton": {
                "instance_group_count": 4,
                "server_target_qps": 7100,
                "start_from_device": false,
                "use_triton": true
            }
        },
        "deque_timeout_us": 30000,
        "gpu_batch_size": 8,
        "gpu_inference_streams": 4,
        "server_target_qps": 7550,
        "start_from_device": true,
        "use_cuda_thread_per_device": true
    },
    "A10x1": {
        "config_ver": {
            "triton": {
                "instance_group_count": 4,
                "server_target_qps": 230,
                "start_from_device": false,
                "use_triton": true
            }
        },
        "deque_timeout_us": 30000,
        "gpu_batch_size": 8,
        "gpu_inference_streams": 4,
        "server_target_qps": 250,
        "start_from_device": true,
        "use_cuda_thread_per_device": true
    },
    "A10x8": {
        "scales": {
            "A10x1": {
                "server_target_qps": 8.0
            }
        }
    },
    "T4x1": {
        "config_ver": {
            "triton": {
                "instance_group_count": 4,
                "server_target_qps": 110,
                "use_triton": true
            }
        },
        "deque_timeout_us": 2000,
        "gpu_batch_size": 2,
        "gpu_inference_streams": 4,
        "server_target_qps": 110,
        "use_cuda_thread_per_device": false
    },
    "T4x20": {
        "config_ver": {
            "triton": {
                "gpu_batch_size": 2,
                "instance_group_count": 2,
                "server_target_qps": 2280,
                "use_triton": true
            }
        },
        "deque_timeout_us": 30000,
        "gpu_batch_size": 4,
        "gpu_inference_streams": 2,
        "server_target_qps": 2400,
        "use_cuda_thread_per_device": true
    },
    "T4x8": {
        "config_ver": {
            "triton": {
                "instance_group_count": 2,
                "server_target_qps": 720,
                "use_triton": true
            }
        },
        "deque_timeout_us": 30000,
        "gpu_batch_size": 4,
        "gpu_inference_streams": 1,
        "server_target_qps": 1000,
        "use_cuda_thread_per_device": true
    },
    "TitanRTXx1": {
        "config_ver": {
            "triton": {
                "instance_group_count": 4,
                "server_target_qps": 332,
                "use_triton": true
            }
        },
        "deque_timeout_us": 2000,
        "gpu_batch_size": 32,
        "gpu_inference_streams": 4,
        "server_target_qps": 332,
        "use_cuda_thread_per_device": true
    },
    "TitanRTXx4": {
        "config_ver": {
            "triton": {
                "instance_group_count": 4,
                "server_target_qps": 1600,
                "use_triton": true
            }
        },
        "deque_timeout_us": 30000,
        "gpu_batch_size": 4,
        "gpu_inference_streams": 2,
        "server_target_qps": 1630,
        "use_cuda_thread_per_device": true
    },
    "benchmark": "ssd-resnet34",
    "default": {
        "active_sms": 100,
        "gpu_copy_streams": 4,
        "input_dtype": "int8",
        "input_format": "linear",
        "map_path": "data_maps/coco/val_map.txt",
        "precision": "int8",
        "tensor_path": "${PREPROCESSED_DATA_DIR}/coco/val2017/SSDResNet34/int8_linear",
        "use_deque_limit": true,
        "use_graphs": false
    },
    "scenario": "Server"
}