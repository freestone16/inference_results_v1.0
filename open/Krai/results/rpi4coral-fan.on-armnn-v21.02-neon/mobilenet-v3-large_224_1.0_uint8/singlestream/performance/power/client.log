client 2021-03-07 16:36:08,221 [INFO] Sending command to the server: 'mlcommons/power client v3'
client 2021-03-07 16:36:08,223 [INFO] Got response: 'mlcommons/power server v3'
client 2021-03-07 16:36:08,224 [INFO] Synchronizing with the server and with time.google.com...
client 2021-03-07 16:36:08,282 [INFO] NTP:offset = -0.003 s, delay = 0.031 s 
client 2021-03-07 16:36:08,282 [INFO] Sending command to the server: 'time'
client 2021-03-07 16:36:08,284 [INFO] Got response: '1615134968.28142'
client 2021-03-07 16:36:08,284 [INFO] The time difference between the client and the server is within range 1.268 ms..3.264 ms
client 2021-03-07 16:36:08,284 [INFO] Sending command to the server: 'new,,b8ced7bc-63c6-4d11-9568-d846c43596aa'
client 2021-03-07 16:36:08,289 [INFO] Got response: 'OK 2021-03-07_16-36-08,231d640a-d387-4ed8-a676-d63fcc847029'
client 2021-03-07 16:36:08,289 [INFO] Session id is '2021-03-07_16-36-08'
client 2021-03-07 16:36:08,289 [INFO] Sources: {"sources": {"client.py": "d1e75cb4b26101220ebd242e584cf3ca5d8f1996", "lib/__init__.py": "da39a3ee5e6b4b0d3255bfef95601890afd80709", "lib/client.py": "d42bebf5b74cb6ff3997e2a6c68422afac111a28", "lib/common.py": "b0bad80d8fa328a7636027d4d66ff453f8dd7889", "lib/external/ntplib.py": "4da8f970656505a40483206ef2b5d3dd5e81711d", "lib/server.py": "2ed36471c7af565d6c8438b2134edad1d7ddf166", "lib/source_hashes.py": "4cedff274c661cb1504052018fd4f00dfbf624ef", "lib/summary.py": "0db15d783907aa92038281af4e465545c0648ddb", "lib/time_sync.py": "76051226ec89287839723352f4162aaa24e0546a", "server.py": "99e1310e3f76292aef1b8792ce6b8c82f1d44d8b", "tests/unit/test_server.py": "64f11775bfed35232a0e8bb9593c0ff992432c59", "tests/unit/test_source_hashes.py": "cb41a7261eaf7d94ba5c0aae9c523174f6204be3"}, "modules": {"__main__": "client.py", "lib.client": "lib/client.py", "lib.common": "lib/common.py", "lib.external.ntplib": "lib/external/ntplib.py", "lib.source_hashes": "lib/source_hashes.py", "lib.summary": "lib/summary.py", "lib.time_sync": "lib/time_sync.py"}}
client 2021-03-07 16:36:08,290 [INFO] Running workload in ranging mode
client 2021-03-07 16:36:08,290 [INFO] Synchronizing with the server and with time.google.com...
client 2021-03-07 16:36:08,332 [INFO] NTP:offset = -0.007 s, delay = 0.039 s 
client 2021-03-07 16:36:08,332 [INFO] Sending command to the server: 'time'
client 2021-03-07 16:36:08,335 [INFO] Got response: '1615134968.3316603'
client 2021-03-07 16:36:08,335 [INFO] The time difference between the client and the server is within range 1.294 ms..4.144 ms
client 2021-03-07 16:36:08,336 [INFO] Sending command to the server: 'session,2021-03-07_16-36-08,start,ranging'
client 2021-03-07 16:36:36,527 [INFO] Got response: 'OK'
client 2021-03-07 16:36:36,528 [INFO] Running the workload 'ck benchmark program:image-classification-armnn-tflite-loadgen --env.CK_SILENT_MODE=YES --skip_print_timers --dep_add_tags.compiler=gcc,v9 --dep_add_tags.python=v3 --dep_add_tags.mlperf-inference-src=r1.0 --dep_add_tags.weights=mobilenet,v3-large_224_1.0_uint8 --dep_add_tags.images=crop.875,preprocessed,using-opencv --dep_add_tags.library=armnn,rel.21.02,neon --env.CK_LOADGEN_DATASET_SIZE=1024 --env.USE_NEON=1 --env.CK_LOADGEN_MODE=PerformanceOnly --env.CK_LOADGEN_SCENARIO=SingleStream --env.CK_FAN_MODE=on --env.CK_LOADGEN_TARGET_LATENCY=$CK_LOADGEN_TARGET_LATENCY --skip_stat_analysis --process_multi_keys --repetitions=1 --record --record_repo=local --record_uoa=mlperf-open-rpi4coral-armnn-v21.02-neon-mobilenet-v3-large_224_1.0_uint8-singlestream-performance-target_latency.$CK_LOADGEN_TARGET_LATENCY-fan_mode.on-power.workload --tags=mlperf,division.open,task.image-classification,platform.rpi4coral,scenario.singlestream,mode.performance,workload.mobilenet-v3-large_224_1.0_uint8,preprocessed_using.opencv,inference_engine.armnn,inference_engine_version.v21.02,inference_engine_backend.neon,fan_mode.on,target_latency.$CK_LOADGEN_TARGET_LATENCY,power.workload "@@@{\'meta\': {\'ck_benchmark_program\': \'ck benchmark program:image-classification-armnn-tflite-loadgen --env.CK_SILENT_MODE=YES --skip_print_timers --dep_add_tags.compiler=gcc,v9 --dep_add_tags.python=v3 --dep_add_tags.mlperf-inference-src=r1.0 --dep_add_tags.weights=mobilenet,v3-large_224_1.0_uint8 --dep_add_tags.images=crop.875,preprocessed,using-opencv --dep_add_tags.library=armnn,rel.21.02,neon --env.CK_LOADGEN_DATASET_SIZE=1024 --env.USE_NEON=1 --env.CK_LOADGEN_MODE=PerformanceOnly --env.CK_LOADGEN_SCENARIO=SingleStream --env.CK_FAN_MODE=on --env.CK_LOADGEN_TARGET_LATENCY=$CK_LOADGEN_TARGET_LATENCY --skip_stat_analysis --process_multi_keys --repetitions=1 --record --record_repo=local --record_uoa=mlperf-open-rpi4coral-armnn-v21.02-neon-mobilenet-v3-large_224_1.0_uint8-singlestream-performance-target_latency.$CK_LOADGEN_TARGET_LATENCY-fan_mode.on-power.workload --tags=mlperf,division.open,task.image-classification,platform.rpi4coral,scenario.singlestream,mode.performance,workload.mobilenet-v3-large_224_1.0_uint8,preprocessed_using.opencv,inference_engine.armnn,inference_engine_version.v21.02,inference_engine_backend.neon,fan_mode.on,target_latency.$CK_LOADGEN_TARGET_LATENCY,power.workload\'}}"  && mkdir -p "$CK_MLPERF_POWER_CLIENT_LOADGEN_LOGS" && cp "$CK_MLPERF_POWER_CLIENT_LOADGEN_LOGS"/../mlperf_log_* "$CK_MLPERF_POWER_CLIENT_LOADGEN_LOGS"/'
client 2021-03-07 16:47:01,499 [INFO] Sending command to the server: 'session,2021-03-07_16-36-08,stop,ranging'
client 2021-03-07 16:47:12,093 [INFO] Got response: 'OK'
client 2021-03-07 16:47:12,095 [INFO] Running workload in testing mode
client 2021-03-07 16:47:12,095 [INFO] Synchronizing with the server and with time.google.com...
client 2021-03-07 16:47:12,140 [INFO] NTP:offset = -0.007 s, delay = 0.038 s 
client 2021-03-07 16:47:12,140 [INFO] Sending command to the server: 'time'
client 2021-03-07 16:47:12,143 [INFO] Got response: '1615135632.1393976'
client 2021-03-07 16:47:12,144 [INFO] The time difference between the client and the server is within range 1.040 ms..4.710 ms
client 2021-03-07 16:47:12,144 [INFO] Sending command to the server: 'session,2021-03-07_16-36-08,start,testing'
client 2021-03-07 16:47:25,161 [INFO] Got response: 'OK'
client 2021-03-07 16:47:25,162 [INFO] Running the workload 'ck benchmark program:image-classification-armnn-tflite-loadgen --env.CK_SILENT_MODE=YES --skip_print_timers --dep_add_tags.compiler=gcc,v9 --dep_add_tags.python=v3 --dep_add_tags.mlperf-inference-src=r1.0 --dep_add_tags.weights=mobilenet,v3-large_224_1.0_uint8 --dep_add_tags.images=crop.875,preprocessed,using-opencv --dep_add_tags.library=armnn,rel.21.02,neon --env.CK_LOADGEN_DATASET_SIZE=1024 --env.USE_NEON=1 --env.CK_LOADGEN_MODE=PerformanceOnly --env.CK_LOADGEN_SCENARIO=SingleStream --env.CK_FAN_MODE=on --env.CK_LOADGEN_TARGET_LATENCY=$CK_LOADGEN_TARGET_LATENCY --skip_stat_analysis --process_multi_keys --repetitions=1 --record --record_repo=local --record_uoa=mlperf-open-rpi4coral-armnn-v21.02-neon-mobilenet-v3-large_224_1.0_uint8-singlestream-performance-target_latency.$CK_LOADGEN_TARGET_LATENCY-fan_mode.on-power.workload --tags=mlperf,division.open,task.image-classification,platform.rpi4coral,scenario.singlestream,mode.performance,workload.mobilenet-v3-large_224_1.0_uint8,preprocessed_using.opencv,inference_engine.armnn,inference_engine_version.v21.02,inference_engine_backend.neon,fan_mode.on,target_latency.$CK_LOADGEN_TARGET_LATENCY,power.workload "@@@{\'meta\': {\'ck_benchmark_program\': \'ck benchmark program:image-classification-armnn-tflite-loadgen --env.CK_SILENT_MODE=YES --skip_print_timers --dep_add_tags.compiler=gcc,v9 --dep_add_tags.python=v3 --dep_add_tags.mlperf-inference-src=r1.0 --dep_add_tags.weights=mobilenet,v3-large_224_1.0_uint8 --dep_add_tags.images=crop.875,preprocessed,using-opencv --dep_add_tags.library=armnn,rel.21.02,neon --env.CK_LOADGEN_DATASET_SIZE=1024 --env.USE_NEON=1 --env.CK_LOADGEN_MODE=PerformanceOnly --env.CK_LOADGEN_SCENARIO=SingleStream --env.CK_FAN_MODE=on --env.CK_LOADGEN_TARGET_LATENCY=$CK_LOADGEN_TARGET_LATENCY --skip_stat_analysis --process_multi_keys --repetitions=1 --record --record_repo=local --record_uoa=mlperf-open-rpi4coral-armnn-v21.02-neon-mobilenet-v3-large_224_1.0_uint8-singlestream-performance-target_latency.$CK_LOADGEN_TARGET_LATENCY-fan_mode.on-power.workload --tags=mlperf,division.open,task.image-classification,platform.rpi4coral,scenario.singlestream,mode.performance,workload.mobilenet-v3-large_224_1.0_uint8,preprocessed_using.opencv,inference_engine.armnn,inference_engine_version.v21.02,inference_engine_backend.neon,fan_mode.on,target_latency.$CK_LOADGEN_TARGET_LATENCY,power.workload\'}}"  && mkdir -p "$CK_MLPERF_POWER_CLIENT_LOADGEN_LOGS" && cp "$CK_MLPERF_POWER_CLIENT_LOADGEN_LOGS"/../mlperf_log_* "$CK_MLPERF_POWER_CLIENT_LOADGEN_LOGS"/'
client 2021-03-07 16:57:55,023 [INFO] Sending command to the server: 'session,2021-03-07_16-36-08,stop,testing'
client 2021-03-07 16:58:05,341 [INFO] Got response: 'OK'
client 2021-03-07 16:58:05,343 [INFO] Done runs
