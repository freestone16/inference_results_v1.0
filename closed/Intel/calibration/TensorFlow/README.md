# TensorFLow ResNet50-v1.5 for MLPerf v0.7 inference

## Description

The ResNet50 INT8 model is offline generated by [Intel Low Precision Optimization Tool](https://github.com/intel/lp-opt-tool.git) based on [FP32 model](https://zenodo.org/record/2535873/files/resnet50_v1.pb) and the calibration dataset provided by mlperf in [here](https://github.com/mlperf/inference/blob/master/calibration/ImageNet/cal_image_list_option_1.txt)


The ResNet50 BF16 model is offline converted by auto-mixed-precision graph optimizer from TensorFlow.

## Steps for INT8 calibration

```bash

pip install intel-tensorflow==2.3.0
wget https://zenodo.org/record/2535873/files/resnet50_v1.pb
git clone https://github.com/intel/lp-opt-tool.git
cd lp-opt-tool
git checkout mlperf_v0.7
python setup.py install
cd ..
git clone --recurse-submodules https://github.com/mlperf/inference.git
cd inference
git reset --hard bfbda5fc419364c3f71b5b1640f6c00e7675b212
git apply mlperf.patch
cd vision/classification_and_detection
MODEL_DIR=<dir_to_resnet50_v1.pb> DATA_DIR=<dir_to_ILSVRC2012_img_val> ./run_local.sh tf resnet50 cpu --accuracy --calib-dataset-list=../../calibration/ImageNet/cal_image_list_option_1.txt --tune

```

A graph named int8_resnet50_v1.pb will be generated in the current working dir (inference/vision/classification_and_detection).

## Steps for generating BF16 model

TensorFlow framework has auto-mixed-precision grappler optimizer to convert several operators into bfloat16 precision for CPU. Run the following python script

```bash

TF_AUTO_MIXED_PRECISION_GRAPH_REWRITE_CLEARLIST_ADD=Pad,BiasAdd TF_AUTO_MIXED_PRECISION_GRAPH_REWRITE_GRAYLIST_REMOVE=BiasAdd python convert_fp32_to_bf16.py

```



